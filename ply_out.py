#!/usr/bin/env python
#      -*-mode: python -*-    -*- coding: utf-8 -*-
"""


"""

import serializer
import plugin
import bnf_tools
from cStringIO import StringIO

import AST

class Serializer(serializer.General):

    def __init__(self, indent_factor):
        super(Serializer, self).__init__(indent_factor=indent_factor)
        self.tokens = bnf_tools.TokenSet()

    def generate_parser(self, root):

        root = self.tokens.ingest(root)
        bnf_tools.convert_to_yacc_form(root)

        self.do_lex_prolog()
        self.out(self.tokens.for_lex())
        self.do_lex_epilog()
        self.do_yacc_prolog()
        self.do_Grammar(root)
        self.do_yacc_epilog()
  
    def do_str(self, obj):
        self.outk(repr(obj))

    #def do_Sequence(self, obj):

    def do_Grammar(self, obj):
        for i in obj.productions:
            self.do(i)
            self.out()


    def do_Production(self, obj):
        self.out()
        if len(obj.branches):
            count = 0
            for branch in obj.branches:
                count += 1
                self.do_branch(branch, obj.name, count)
        else:
            self.do_branch(branch)
        self.out()

    def do_branch(self, obj, name, count):
        if count:
            index = "_%d" % count
        else:
            index = ""
        self.lend()
        self.out("def p_%s%s(t):" % (name, index))
        self.indent += 1
        self.out("'''%s : " % name, keep=1)
        self.do(obj)
        self.out(" '''")
        self.out("pass")
        self.indent -= 1


    def do_Seq(self, obj):
        self.do(obj.left)
        self.out(" ", keep=0.8)
        self.do(obj.right)

    def do_Alt(self, obj):
        #self.out("(")
        self.do(obj.left)
        self.lend()
        self.out(" | ", keep=0.6)
        self.do(obj.right)
        #self.out(")")

    def do_Reference(self, obj):
        self.outk(obj.name)

    def do_Precedence(self, obj):
        self.out("(", keep=0.9)
        self.do(obj.expr)
        self.out(")", keep=0.9)
        self.out(" %prec ", obj.reference, keep=0.9)


    def do_Property(self, obj):
        self.outk(obj.property)
        self.outk("::(")    # how do to parens only when necessary?
        self.do(obj.expr)
        self.outk(")")

    def do_Plus(self, obj):
        self.outk("(")
        self.do(obj.expr)
        self.outk(")")
        self.outk("+")

    def do_Optional(self, obj):
        self.outk("(")
        self.do(obj.expr)
        self.outk(")")
        self.outk("?")


    def do_Star(self, obj):
        self.outk("(")
        self.do(obj.expr)
        self.outk(")")
        self.outk("*")

    def do_Literal(self, obj):
        self.outk('"', obj.text, '"')    # escaping

    def do_lex_prolog(self):
        self.out("#!/usr/bin/env python2.5")
        self.out("#      -*-mode: python -*-    -*- coding: utf-8 -*-")
        self.out("'Generated by ply_out.py'")
        self.out("")
        self.out("import re")        
        self.out("")
        self.out("import ply.yacc")
        self.out("import ply.lex")
        self.out("")
        self.out("import AST")
        self.out("import plugin")
        self.out("import error")
        self.out("\n"
                 "tokens = []\n"
                 "\n"
                 "reserved = {}\n"
                 "\n")
        self.out("# END LEX PROLOG")

    def do_lex_epilog(self):
        self.out("# BEGIN LEX EPILOG")
        self.out("\n"
                 "tokens.extend(reserved.values())\n"
                 "\n"
                 "\n"
                 "def t_ID(t):\n"
                 r"   r'[a-zA-Z_][a-zA-Z_0-9]*'" + "\n"
                 "   t.type = reserved.get(t.value,'ID')\n"
                 "   return t\n"
                 "\n"
                 "def t_COMMENT(t):\n"
                 r"   r'\#.*'" + "\n"
                 "   pass\n"
                 "   # No return value. Token discarded\n"
                 "\n"
                 "# Define a rule so we can track line numbers\n"
                 "def t_newline(t):\n"
                 r"    r'\n+'" + "\n"
                 "    t.lexer.lineno += len(t.value)\n"
                 "\n"
                 "# A string containing ignored characters (spaces and tabs)\n"
                 "t_ignore  = ' \t'\n"
                 "\n"
                 "# Error handling rule\n"
                 "def t_error(t):\n"
                 "    print \"Illegal character '%s'\" % t.value[0]\n"
                 "    t.lexer.skip(1)\n"
                 "\n"
                 "# Build the lexer\n"
                 "lexer = ply.lex.lex(debug=0)\n"
                 "")
        
        self.out("# END LEX EPILOG")

    def do_yacc_prolog(self):
        self.out("# BEGIN YACC PROLOG")
        self.out("# END YACC PROLOG")

    def do_yacc_epilog(self):
        self.out("# BEGIN YACC EPILOG")
        self.out("# END YACC EPILOG")
        self.out(self.newline)


class Plugin (plugin.OutputPlugin):
   """Generate the PLY-compatible Python code for parsing the given grammar.
   """

   id=__name__

   options = [
       plugin.Option('indent_factor', 'Number of spaces to indent each level',
                     default="4"),
       ]
 
   def __init__(self, **kwargs):
       # We *could* make the Plugin *be* the Serializer, but that feels a
       # little too confusing for me right this moment.
       self.ser = Serializer(**kwargs)

   def serialize(self, doc, output_stream):
       self.ser.output_stream = output_stream
       self.ser.generate_parser(doc)

plugin.register(Plugin)

        
